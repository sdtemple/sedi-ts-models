{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4b84714-7e78-4bf7-b4dc-861991a91e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep learning\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c78be7-866c-489a-8823-baf0b968e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_filename = 'standard_scaler.joblib'\n",
    "loaded_scaler = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93af6878-ad18-4f8b-8424-8cd7cbff977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this \n",
    "dataset = 'training' # or testing\n",
    "num_years = 24 # will depend on training (24) or testing (6)\n",
    "num_stations = 50 # number of stations in array to be made\n",
    "\n",
    "# windowing\n",
    "window_size = 60 # number of days in a single row\n",
    "window_step = 20 # sliding window if you want nonoverlapping versus overlapping days\n",
    "total_days = 366\n",
    "window_starts = [_+1 for _ in range(0,(366//window_size)*window_size-window_size+1,window_step)]\n",
    "num_windows = len(window_starts)\n",
    "\n",
    "num_var = 85 # this is number of prechosen variables (must adjust if you drop out some columns/features)\n",
    "target_file = f\"{dataset}/Y-size{window_size}-step{window_step}-station{num_stations}.pt\"\n",
    "covariates_file = f\"{dataset}/X-size{window_size}-step{window_step}-station{num_stations}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6f2384-268c-42d4-964d-032ddaf33853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station 3\n",
      "Station 6\n",
      "Station 9\n",
      "Station 12\n",
      "Station 15\n",
      "Station 18\n",
      "Station 21\n",
      "Station 24\n",
      "Station 27\n",
      "Station 30\n",
      "Station 33\n",
      "Station 36\n",
      "Station 39\n",
      "Station 42\n",
      "Station 45\n",
      "Station 48\n",
      "Station 51\n",
      "Station 54\n",
      "Station 57\n",
      "Station 60\n",
      "Station 63\n",
      "Station 66\n",
      "Station 69\n",
      "Station 72\n",
      "Station 75\n",
      "Station 78\n",
      "Station 81\n",
      "Station 84\n",
      "Station 87\n",
      "Station 90\n",
      "Station 93\n",
      "Station 96\n",
      "Station 99\n",
      "Station 102\n",
      "Station 105\n",
      "Station 108\n",
      "Station 111\n",
      "Station 114\n",
      "Station 117\n",
      "Station 120\n",
      "Station 123\n",
      "Station 126\n",
      "Station 129\n",
      "Station 132\n",
      "Station 135\n",
      "Station 138\n",
      "Station 141\n",
      "Station 144\n",
      "Station 147\n",
      "Station 150\n",
      "Station 153\n",
      "Station 156\n",
      "Station 159\n",
      "Station 162\n",
      "Station 165\n",
      "Station 168\n",
      "Station 171\n",
      "Station 174\n",
      "Station 177\n",
      "Station 180\n",
      "Station 183\n",
      "Station 186\n",
      "Station 189\n",
      "Station 192\n",
      "Station 195\n",
      "Station 198\n",
      "Station 201\n",
      "Station 204\n",
      "Station 207\n",
      "Station 210\n",
      "Station 213\n",
      "Station 216\n",
      "Station 219\n",
      "Station 222\n",
      "Station 225\n",
      "Station 228\n",
      "Station 231\n",
      "Station 234\n",
      "Station 237\n",
      "Station 240\n",
      "Station 243\n",
      "Station 246\n",
      "Station 249\n",
      "Station 252\n",
      "Station 255\n",
      "Station 258\n",
      "Station 261\n",
      "Station 264\n",
      "Station 267\n",
      "Station 270\n",
      "Station 273\n",
      "Station 276\n",
      "Station 279\n",
      "Station 282\n",
      "Station 285\n",
      "Station 288\n"
     ]
    }
   ],
   "source": [
    "# initialize arrays\n",
    "Y = torch.zeros(num_years * num_stations * num_windows, window_size)\n",
    "X = torch.zeros(num_years * num_stations * num_windows, window_size, num_var)\n",
    "\n",
    "# run through all datasets into tensors\n",
    "ctr = 0\n",
    "for _ in range(1, num_stations + 1):\n",
    "    if (_) % 3 == 0:\n",
    "        print(f'Station {_}')\n",
    "    table = pd.read_csv(f'{dataset}/{_}.csv')    \n",
    "    numeric_columns = table.columns.tolist()[3:]\n",
    "    # datetime processing\n",
    "    table['date'] = pd.to_datetime(table['date'])\n",
    "    table['year'] = table['date'].dt.year\n",
    "    table['dayofyear'] = table['date'].dt.dayofyear\n",
    "    years = table.year.unique()\n",
    "    # subset by year to get time series\n",
    "    for yr in years:\n",
    "        for wn in window_starts:\n",
    "            dayofyear1 = wn\n",
    "            dayofyear2 = wn + window_size\n",
    "            subtable = table[(table.year == yr) & (table.dayofyear >= dayofyear1) & (table.dayofyear < dayofyear2)]\n",
    "            yx = subtable[numeric_columns].to_numpy()\n",
    "            scaled_yx = loaded_scaler.transform(yx)\n",
    "            y = torch.tensor(scaled_yx[:,0])\n",
    "            x = torch.tensor(scaled_yx[:,1:])\n",
    "            Y[ctr] = y\n",
    "            X[ctr] = x\n",
    "            ctr += 1\n",
    "\n",
    "    \n",
    "    # # define variables\n",
    "    # target = 'minmax_log_sedyld'\n",
    "    # covariates = table.columns.tolist()[4:]\n",
    "    # # datetime processing\n",
    "    # table['date'] = pd.to_datetime(table['date'])\n",
    "    # table['year'] = table['date'].dt.year\n",
    "    # table['dayofyear'] = table['date'].dt.dayofyear\n",
    "    # years = table.year.unique()\n",
    "    # # subset by year to get time series\n",
    "    # for yr in years:\n",
    "    #     for wn in window_starts:\n",
    "    #         dayofyear1 = wn\n",
    "    #         dayofyear2 = wn + window_size\n",
    "    #         subtable = table[(table.year == yr) & (table.dayofyear >= dayofyear1) & (table.dayofyear < dayofyear2)]\n",
    "    #         y = torch.tensor(subtable[target].to_numpy())\n",
    "    #         x = torch.tensor(subtable[covariates].to_numpy())\n",
    "    #         Y[ctr] = y\n",
    "    #         X[ctr] = x\n",
    "    #         ctr += 1\n",
    "\n",
    "# save the tensors\n",
    "torch.save(Y, target_file)\n",
    "torch.save(X, covariates_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hood River",
   "language": "python",
   "name": "hoodriver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
