{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b84714-7e78-4bf7-b4dc-861991a91e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7ab2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_filename = 'X_scaler.joblib'\n",
    "X_loaded_scaler = joblib.load(scaler_filename)\n",
    "scaler_filename = 'Y_scaler.joblib'\n",
    "Y_loaded_scaler = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af6878-ad18-4f8b-8424-8cd7cbff977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_stations = 50 # number of stations in array to be made\n",
    "\n",
    "# windowing\n",
    "window_size = 30 # number of days in a single row\n",
    "window_step = 10 # sliding window if you want nonoverlapping versus overlapping days\n",
    "total_days = 366\n",
    "window_starts = [_+1 for _ in range(0,(366//window_size)*window_size-window_size+1,window_step)]\n",
    "num_windows = len(window_starts)\n",
    "\n",
    "num_var = 77 - 1 # this is number of prechosen variables (must adjust if you drop out some columns/features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db6e4e8",
   "metadata": {},
   "source": [
    "### Training data folded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df01a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this\n",
    "dataset = 'training' # or testing\n",
    "target_file = f\"{dataset}/Y-size{window_size}-step{window_step}-station{num_stations}\"\n",
    "covariates_file = f\"{dataset}/X-size{window_size}-step{window_step}-station{num_stations}\"\n",
    "units_file = f\"{dataset}/Z-size{window_size}-step{window_step}-station{num_stations}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c331e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = 1\n",
    "table = pd.read_csv(f'{dataset}/{_}.csv')    \n",
    "numeric_columns = table.columns.tolist()[3:]\n",
    "# datetime processing\n",
    "table['date'] = pd.to_datetime(table['date'])\n",
    "table['year'] = table['date'].dt.year\n",
    "years = table['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=8, shuffle=True, random_state=42)\n",
    "for fold_train, fold_val in kf.split(years):\n",
    "    fold_years = years[fold_val]\n",
    "    num_years = len(fold_years)\n",
    "    print(fold_years)\n",
    "\n",
    "    # initialize arrays\n",
    "    Y = np.zeros((num_years * num_stations * num_windows, window_size))\n",
    "    X = np.zeros((num_years * num_stations * num_windows, window_size, num_var))\n",
    "    Z = np.zeros((num_years * num_stations * num_windows, window_size))\n",
    "\n",
    "    # run through all datasets into tensors\n",
    "    ctr = 0\n",
    "    for _ in range(1, num_stations + 1):\n",
    "        if (_) % 10 == 0:\n",
    "            print(f'Station {_}')\n",
    "        table = pd.read_csv(f'{dataset}/{_}.csv')    \n",
    "        numeric_columns = table.columns.tolist()[3:]\n",
    "        # datetime processing\n",
    "        table['date'] = pd.to_datetime(table['date'])\n",
    "        table['year'] = table['date'].dt.year\n",
    "        table = table[table.year.isin(fold_years)]\n",
    "        table['dayofyear'] = table['date'].dt.dayofyear\n",
    "        yrs = table.year.unique()\n",
    "        # subset by year to get time series\n",
    "        for yr in yrs:\n",
    "            for wn in window_starts:\n",
    "                dayofyear1 = wn\n",
    "                dayofyear2 = wn + window_size\n",
    "                subtable = table[(table.year == yr) & (table.dayofyear >= dayofyear1) & (table.dayofyear < dayofyear2)]\n",
    "                x = subtable[numeric_columns[1:]].to_numpy()\n",
    "                y = subtable[numeric_columns[0]].to_numpy().reshape(-1,1)\n",
    "                scaled_X = X_loaded_scaler.transform(x)\n",
    "                scaled_Y = Y_loaded_scaler.transform(y)\n",
    "                Y[ctr] = scaled_Y.reshape(1,-1)\n",
    "                X[ctr] = scaled_X\n",
    "                Z[ctr] = _\n",
    "                ctr += 1\n",
    "\n",
    "    years_suffix = ''.join([f'_{yr}' for yr in fold_years])\n",
    "    \n",
    "    # save the arrays\n",
    "    np.save(f'{target_file}{years_suffix}.npy', Y)\n",
    "    np.save(f'{covariates_file}{years_suffix}.npy', X)\n",
    "    np.save(f'{units_file}{years_suffix}.npy', Z)\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070a74dd",
   "metadata": {},
   "source": [
    "### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6173278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify this\n",
    "num_years = 6 # will depend on training (24) or testing (6)\n",
    "dataset = 'testing' # or testing\n",
    "target_file = f\"{dataset}/Y-size{window_size}-step{window_step}-station{num_stations}.npy\"\n",
    "covariates_file = f\"{dataset}/X-size{window_size}-step{window_step}-station{num_stations}.npy\"\n",
    "units_file = f\"{dataset}/Z-size{window_size}-step{window_step}-station{num_stations}.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize arrays\n",
    "Y = np.zeros((num_years * num_stations * num_windows, window_size))\n",
    "X = np.zeros((num_years * num_stations * num_windows, window_size, num_var))\n",
    "Z = np.zeros((num_years * num_stations * num_windows, window_size))\n",
    "\n",
    "# run through all datasets into tensors\n",
    "ctr = 0\n",
    "for _ in range(1, num_stations + 1):\n",
    "    if (_) % 10 == 0:\n",
    "        print(f'Station {_}')\n",
    "    table = pd.read_csv(f'{dataset}/{_}.csv')    \n",
    "    numeric_columns = table.columns.tolist()[3:]\n",
    "    # datetime processing\n",
    "    table['date'] = pd.to_datetime(table['date'])\n",
    "    table['year'] = table['date'].dt.year\n",
    "    table['dayofyear'] = table['date'].dt.dayofyear\n",
    "    years = table.year.unique()\n",
    "    # subset by year to get time series\n",
    "    for yr in years:\n",
    "        for wn in window_starts:\n",
    "            dayofyear1 = wn\n",
    "            dayofyear2 = wn + window_size\n",
    "            subtable = table[(table.year == yr) & (table.dayofyear >= dayofyear1) & (table.dayofyear < dayofyear2)]\n",
    "            x = subtable[numeric_columns[1:]].to_numpy()\n",
    "            y = subtable[numeric_columns[0]].to_numpy().reshape(-1,1)\n",
    "            scaled_X = X_loaded_scaler.transform(x)\n",
    "            scaled_Y = Y_loaded_scaler.transform(y)\n",
    "            Y[ctr] = scaled_Y.reshape(1,-1)\n",
    "            X[ctr] = scaled_X\n",
    "            Z[ctr] = _\n",
    "            ctr += 1\n",
    "\n",
    "# save the arrays\n",
    "np.save(target_file, Y)\n",
    "np.save(covariates_file, X)\n",
    "np.save(units_file, Z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hoodriver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
